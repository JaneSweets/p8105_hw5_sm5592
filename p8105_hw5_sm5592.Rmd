---
title: "Homework 5"
author: "Shaolei Ma"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

First, import the data.

```{r}
homicide_df =
  read_csv("data/homicide-data.csv")
```

The data contains `r nrow(homicide_df)` observations and `r ncol(homicide_df)` variables related to the victim's biographical information and the location and disposition of the case.

Then, do some data cleaning and analysis.

```{r}
homicide_df = 
  homicide_df |> 
  janitor::clean_names() |> 
  mutate(city_state = str_c(city, ", ", state))

homicide_city_df = 
  homicide_df |> 
  group_by(city_state) |> 
  summarise(
    homicide_num = n(), 
    unsolved_num = sum(disposition == "Closed without arrest" | disposition == "Open/No arrest"))
```

Then, the total number of homicides is `r sum(homicide_city_df$homicide_num)`, and the total number of unsolved homicides is `r sum(homicide_city_df$unsolved_num)`.

For the city of Baltimore, MD:
```{r}
baltimore_df =
  homicide_city_df |> 
  filter(city_state == "Baltimore, MD")

baltimore_prop = prop.test(pull(baltimore_df, unsolved_num), pull(baltimore_df, homicide_num))

baltimore_prop_df = 
  baltimore_prop |> 
  broom::tidy(baltimore_prop)
```

The estimated proportion of unsolved homicides is `r pull(baltimore_prop_df, estimate) |> round(3)`, and the confidence interval is [`r pull(baltimore_prop_df, conf.low) |> round(3)`, `r pull(baltimore_prop_df, conf.high) |> round(3)`].

```{r}
prop_tidy = function(x, n) {
  
  result_df =
    prop.test(x, n) |> 
    broom::tidy()
  
  tibble(
    estimate = pull(result_df, estimate),
    conf.low = pull(result_df, conf.low),
    conf.high = pull(result_df, conf.high)
  )
  
}

unsolved_prop_df = 
  homicide_city_df |> 
  mutate(prop_estimate = map2(unsolved_num, homicide_num, prop_tidy)) |> 
  unnest(prop_estimate)

unsolved_prop_df |> head()
```

The `unsolved_prop_df` dataframe collects the proportion estimate and CI for each city.

```{r}
unsolved_prop_df |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) # rotate labels
```

As illustrated in the plot, Tulsa has the lowest estimate and the widest confidence interval, while Chicago has the highest estimate and the most narrow confidence interval.

# Problem 2
```{r}
import_data = function(url_path = "data/problem2_data/", name) {
  
  read_csv(str_c(url_path, name))
  
}

participants_df =
  tibble(names = list.files("data/problem2_data/")) |> # start with file names
  mutate(dat = map(names, import_data, url_path = "data/problem2_data/")) |> # read in data
  unnest(dat) |> 
  mutate(names = str_remove(names, ".csv")) |> #delete suffix
  separate(names, into = c("arm", "id"), sep = "_") |> 
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "observation",
    names_prefix = "week_",
    names_transform = list(week = as.numeric)
  )

participants_df |> 
  ggplot(aes(x = week, y = observation, group = id, color = id)) +
  geom_line() +
  facet_grid(. ~ arm)
```

From the spaghetti plot, the observation values of the experimental arm increase over time, while those of the control arm fluctuates within a certain range.

# Problem 3

```{r}

```

